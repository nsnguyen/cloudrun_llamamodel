{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyen/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# need to run download_llama.sh\n",
    "\n",
    "model_dir = \"./llama-2-7b-chat-hf\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "\"text-generation\",\n",
    "model=model,\n",
    "tokenizer=tokenizer,\n",
    "torch_dtype=torch.float16,\n",
    "device_map=\"auto\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "'I have potatoes and steak. What can I cook for dinner?\\n',\n",
    "do_sample=True,\n",
    "top_k=10,\n",
    "num_return_sequences=1,\n",
    "eos_token_id=tokenizer.eos_token_id,\n",
    "max_length=400,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have potatoes and steak. What can I cook for dinner?\n",
      "Answer: You could make a hearty steak and potato Stir Fry for dinner! Simply season the steak with your favorite spices and cook it in a pan until it's cooked to your desired level of doneness. Then, add sliced potatoes to the pan and cook until they're tender and crispy. Serve the steak and potatoes together on a plate and enjoy!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "  print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.29s/it]\n",
      "/Users/nguyen/.pyenv/versions/3.11.4/lib/python3.11/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-chat-hf\", token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pipe(\n",
    "'I have potatoes and steak. What can I cook for dinner?',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have potatoes and steak. What can I cook for dinner?\n",
      "A: You can make a delicious steak and potato dinner by grilling or pan-frying the steak and roasting or boiling the potatoes. Here are some specific recipe ideas:\n",
      "\n",
      "1. Steak and Potato Grill: Grill the steak to your desired level of doneness and serve it with roasted potatoes. You can season the potatoes with olive oil, salt, and pepper, and roast them in the oven until they're tender and crispy.\n",
      "2. Steak and Potato Stir-Fry: Slice the steak into thin strips and stir-fry it with diced potatoes, onions, and your favorite seasonings. Serve the stir-fry over rice or noodles.\n",
      "3. Potato and Steak Shepherd's Pie: Boil the potatoes until they're tender, then mash them and mix them with ground beef, salt, and pepper. Pour the mixture into a baking dish and top it with another layer of mashed potatoes. Bake the shepherd's pie in the oven until the potatoes are golden brown and crispy.\n",
      "4. Steak and Potato Fajitas: Slice the steak into thin strips and cook it with diced potatoes, onions, and bell peppers. Serve the fajitas with warm flour or corn tortillas and your favorite toppings, such as salsa, avocado, and sour cream.\n",
      "\n",
      "These are just a few ideas to get you started. You can also experiment with different seasonings and spices to add more flavor to your steak and potato dishes. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences:\n",
    "  print(f\"{seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TheBloke/Llama-2-7B-Chat-GGUF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
